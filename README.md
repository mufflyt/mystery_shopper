# Appointment Wait Times: A Mystery Caller Study

## For next time: 
* To callers:  Do NOT close the entry until you get a green light for a file to complete.  Do NOT ignore the pop-up notices.  Please print off the excel document and have them cross off calls and highlight when they need to return.  

## Protocol submission
* [FINAL full grant application 7.4.2015.docx](https://github.com/mufflyt/mystery_shopper/files/11963172/FINAL.full.grant.application.7.4.2015.docx)
* [COMIRB application-tmm.pdf](https://github.com/mufflyt/mystery_shopper/files/11963205/COMIRB.application-tmm.pdf)
* There is a Word version of the COMIRB application in the directory called "COMIRB Protocol-template.doc".
* [COMIRB application-for-protocol-review.pdf](https://github.com/mufflyt/mystery_shopper/files/11987004/COMIRB.application-for-protocol-review.pdf) Further ethical reasoning about the mystery caller process.  
* STROBE Checklist: [STROBE-checklist-v4-combined-PlosMedicine.pdf](https://github.com/mufflyt/mystery_shopper/files/11963484/STROBE-checklist-v4-combined-PlosMedicine.pdf)
* Great ethics reference:  [2013-Secret-shoppers-and-conflicts-of-in.pdf](https://github.com/mufflyt/mystery_shopper/files/11963538/2013-Secret-shoppers-and-conflicts-of-in.pdf)

## SPARO Approval (Sponsored Programs and Research Office)
* Denver Health approval was given.  
[COMIRB application-for-protocol-review.pdf](https://github.com/mufflyt/mystery_shopper/files/11774684/COMIRB.application-for-protocol-review.pdf)
* See uploaded GitHub file:  `COMIRB Protocol-template.doc`

## Inclusion and Exclusion Criteria
* Inclusion criteria: ENT physician with generalist and subspecialty training listed on enthealth.org "find a physician" web site.  
* Exclusion criteria: No phone number outside the USA, unable to reach after two phone calls, on hold for 5 minutes or greater

### Publications
* [Muffly FPMRS article.pdf](https://github.com/mufflyt/mystery_shopper/files/11963277/Muffly.FPMRS.article.pdf)
* [Muffly_OBGYN_subspecialist_study.pdf](https://github.com/mufflyt/mystery_shopper/files/11963320/Muffly_OBGYN_subspecialist_study.pdf)
* [FQHC Manuscript_2023June17ANMCJune19NSJune20YHSBtmm.pdf](https://github.com/mufflyt/mystery_shopper/files/11963346/submitted_FQHC.Manuscript_2023June17ANMCJune19NSJune20YHSBtmm.pdf)

## Articles of interest
* [IUD mystery caller study.pdf](https://github.com/mufflyt/mystery_shopper/files/11973808/IUD.mystery.caller.study.pdf)
* [Kunow-2021-A-nationwide-mystery-caller-evaluat.pdf](https://github.com/mufflyt/mystery_shopper/files/11973807/Kunow-2021-A-nationwide-mystery-caller-evaluat.pdf)
* [Copper IUD.pdf](https://github.com/mufflyt/mystery_shopper/files/11973806/Copper.IUD.pdf)
* [lgbtq mystery caller.pdf](https://github.com/mufflyt/mystery_shopper/files/11973805/lgbtq.mystery.caller.pdf)
* [Catholic hospital birth control.pdf](https://github.com/mufflyt/mystery_shopper/files/11973804/Catholic.hospital.birth.control.pdf)
* [Prescription COVID19.pdf](https://github.com/mufflyt/mystery_shopper/files/11973803/Prescription.COVID19.pdf)
* [Access to Developmental Pediatrics Evaluations for At-Risk Children.pdf](https://github.com/mufflyt/mystery_shopper/files/11973802/Access.to.Developmental.Pediatrics.Evaluations.for.At-Risk.Children.pdf)
* [Hamlyn-2016-Accessibility-and-barriers-to-oncol.pdf](https://github.com/mufflyt/mystery_shopper/files/11973801/Hamlyn-2016-Accessibility-and-barriers-to-oncol.pdf)
* [Sandoval-2023-Institutional-barriers-to-clinical-.pdf](https://github.com/mufflyt/mystery_shopper/files/11973800/Sandoval-2023-Institutional-barriers-to-clinical-.pdf)
* [Auditing Access to Specialty Care for Children with Public Insurance.pdf](https://github.com/mufflyt/mystery_shopper/files/11987090/Auditing.Access.to.Specialty.Care.for.Children.with.Public.Insurance.pdf)
* [2014 Merritt Hawkins Survey.pdf](https://github.com/mufflyt/mystery_shopper/files/11987091/2014.Merritt.Hawkins.Survey.pdf)

## Nice references for the materials and methods
* [NEJM appendix Bisgaier supplemental.pdf](https://github.com/mufflyt/mystery_shopper/files/11987083/NEJM.appendix.Bisgaier.supplemental.pdf)
* [medicaid access metaanalysis.pdf](https://github.com/mufflyt/mystery_shopper/files/11987086/medicaid.access.metaanalysis.pdf)
* [Mystery shopping in health service  evaluation.pdf](https://github.com/mufflyt/mystery_shopper/files/11987089/Mystery.shopping.in.health.service.evaluation.pdf)
* [STATE STANDARDS FOR  ACCESS TO CARE IN  MEDICAID MANAGED CARE.pdf](https://github.com/mufflyt/mystery_shopper/files/11987092/STATE.STANDARDS.FOR.ACCESS.TO.CARE.IN.MEDICAID.MANAGED.CARE.pdf)

### Ethics of a Mystery Caller Study
* One ethical issue is informed consent. Participants have a right to know the purpose of the study, the potential risks and benefits, and what will be expected of them. With a mystery caller study, participants may not be aware that they are being observed or that their interactions are part of a research project. This lack of informed consent raises questions about autonomy and the participant's ability to make an informed decision about their participation. It is important to carefully weigh the potential benefits of the study against the potential harm caused by deception and ensure that participants' rights are protected.

* Another ethical concern is the potential harm or distress caused by deception. Deceptive practices can lead to feelings of mistrust, confusion, and discomfort among participants when they discover they were not provided with accurate information. In a mystery caller study, individuals may feel violated or manipulated when they find out their conversations were recorded and analyzed without their knowledge. Researchers have a responsibility to minimize harm and ensure that participants' well-being is prioritized. Clear guidelines for handling and debriefing participants after the study should be in place to address any negative emotional or psychological effects that may arise from the deception.

* To minimize and remedy the risks associated with deception in a mystery caller study, researchers can consider the following measures:

1. Informed Consent: While complete transparency may compromise the study's objectives, it is essential to provide participants with informed consent to the extent possible. Researchers can disclose the general nature of the study without revealing specific details that may compromise the integrity of the research. Participants should understand that they may receive mystery calls or be part of a study involving observational research. This disclosure helps ensure that participants understand their involvement and can make an informed decision about participating.

2. Debriefing: After the study is complete, researchers should conduct a thorough debriefing session with participants. This is an opportunity to explain the study's true purpose, clarify any misconceptions, and address any concerns or emotional reactions that participants may have. During the debriefing, participants should be allowed to withdraw their data if they feel uncomfortable with their participation. Here is a copy of an example debriefing letter: `Muffly-Corbisiero Debriefing Letter.doc`, see directory.  

3. Ethical Review: Researchers should seek ethical review and approval from relevant institutional review boards (IRBs) or ethics committees. These bodies can provide guidance on the study design, participant consent, and the potential risks and benefits of deception. 

4. Minimize Harm: Researchers should take precautions to minimize potential harm caused by deception. This includes ensuring that the study design and procedures are carefully planned and implemented to mitigate any negative impacts on participants.

5. Data Anonymization: All collected data should be properly anonymized and securely stored to protect participants' privacy. Researchers should ensure that any identifiable information is removed or encrypted, reducing the risk of unintended disclosure or breaches of confidentiality.

## Phase 1 - Retrieve and Validate the Telephone Numbers from a Society's Patient facing Database

### Code to evaluate the web site list of physicians
See `scrape.R` for enthealth.org from AAO-HNS.  
![Screen Shot 2023-05-08 at 8 27 35 PM](https://user-images.githubusercontent.com/44621942/236978474-12f9969f-1dee-46e6-a739-4dc7d39c5949.jpg)

See `Orthopedics_physician_directory_scrape.Rmd`.  The data for this project was sourced from the [American Academy Of Orthopaedic Surgeons](https://www7.aaos.org/member/directory/search.aspx?directory=public&_ga=2.25343037.1215811434.1696392931-892052855.1696392931.) website. For the ortho study, I used `Orthopedics_physician_directory_scrape.Rmd` to scrape the patient-facing directory of orthopedic surgeons.  Because the directory is dynamically loaded, I need to use `Rselenium` to create a headless browser to scrape the data.  Installing `Rselenium` for Mac was a pain.  For a Firefox browser:
* Install geckodriver (https://github.com/mozilla/geckodriver/releases.  These are the supported versions: 0.25.0,0.26.0,0.27.0,0.28.0,0.29.0,0.29.1,0.30.0,0.31.0,0.32.0,0.32.1,0.32.2,0.33.0.
* Uninstall the Current Firefox Version:

Open the "Applications" folder on your Mac.
  Locate the "Firefox" application and drag it to the trash to uninstall it.
  Empty the trash to complete the uninstallation.
Visit the Mozilla Firefox archive page to find the version you need: https://ftp.mozilla.org/pub/firefox/releases/
Navigate to the "113.0" directory: https://ftp.mozilla.org/pub/firefox/releases/113.0.1/mac/en-US/
Choose the appropriate installer for your macOS version (usually a .dmg or .tar.gz file).
Download the installer to your computer.
Install firefox version: 117.0.  Make sure that it does not update beyond the current version 117.0.  
Click on "Preferences." In the left sidebar, click on "General." Scroll down to the "Firefox Updates" section. Disable Automatic Updates: In the "Firefox Updates" section, you'll see a dropdown menu next to "Firefox updates." By default, it's set to "Automatically install updates (recommended)." Change this option to "Check for updates, but let you choose to install them."

* Install the development version of RSelenium with `devtools::install_github("ropensci/RSelenium")`
* Check to see if any ports are in use `ps aux | grep webdriver`.  After terminating the processes, you can re-run the `ps` command to confirm that the WebDriver processes are no longer running.
* Check if the port 4567 is open.  `lsof -i :4567`
* Install all programs related to Selenium using homebrew:
```r
brew update
brew upgrade
brew install openjdk@11
pip3 install --upgrade pip
pip3 install selenium
brew services start selenium-server
brew install --cask chromedriver
brew install geckodriver

sudo chmod +x /usr/local/bin/geckodriver
cd /usr/local/bin
pwd
sudo mv "/Users/tylermuffly/Dropbox (Personal)/Mystery shopper/mystery_shopper/aha/geckodriver" /usr/local/bin/
sudo mv my_script /usr/local/bin/
ls /usr/local/bin
xattr -d com.apple.quarantine geckodriver
geckodriver --version

ps aux | grep webdriver
ps
lsof -i :4567
```

```r
remotes::install_github("ropensci/wdman")
devtools::install_github("ropensci/RSelenium")
#remotes::install_github("johndharrison/Rselenium")
#remotes::install_github("johndharrison/wdman")
library(RSelenium)
library(rvest)
library(wdman)
library(netstat)
library(tidyverse)

# Check Available ChromeDriver Versions
library(wdman)
#version requested doesnt match versions available = 100.0.4896.20,100.0.4896.60,104.0.5112.20,104.0.5112.29,107.0.5304.62,108.0.5359.22,108.0.5359.71,112.0.5615.28,112.0.5615.49,113.0.5672.24,113.0.5672.63,114.0.5735.16,114.0.5735.90,85.0.4183.83,85.0.4183.87,86.0.4240.22,87.0.4280.20,91.0.4472.101,92.0.4515.43,94.0.4606.61,95.0.4638.17,96.0.4664.45,97.0.4692.20,98.0.4758.102,98.0.4758.80,99.0.4844.17,99.0.4844.35

wdman::chrome(browser = "chrome", version = "desired_version")
```

```r
rs_driver_object <- rsDriver(browser = 'firefox',
                             geckover = "latest",
                             port = 4447L,
                             verbose = FALSE)
remDr <- rs_driver_object$client
remDr$open() #Opens a browser
remDr$navigate('https://www7.aaos.org/member/directory/search.aspx?directory=public&_ga=2.25343037.1215811434.1696392931-892052855.1696392931.') # Navigates to the webpage
aaos_page <- read_html('https://www7.aaos.org/member/directory/search.aspx?directory=public&_ga=2.25343037.1215811434.1696392931-892052855.1696392931.') #Read html with rvest
state_select_tag <- aaos_page |> html_elements("#ctl00_mainContentPlaceHolder_DdlStateSpecialty") # Find the state dropdown.  Click the selected state
state_names <- state_select_tag |>  # Identify the state dropdown element using its HTML attributes (e.g., id)
  html_elements("option") |> 
  html_text2()
```

### Code to evaluate ACOG list of physicians for generalists
See `~scrape_obgyn_profile_experimental.R` for searching via zip codes.  The zip codes are built using the file `scrape_postal_code.R`.
![Screen Shot 2023-06-16 at 1 35 04 PM](https://github.com/mufflyt/mystery_shopper/assets/44621942/f7c6b827-e860-4081-8b21-cb4775cb9dd0)

### Code to clean up the scrape and get it ready for redcap
See `Clean data from scrape and ready it for redcap.R`.  You can also see exploratory.io dataframe: 'calling_list_from_enthealth.org_aao-hns_results'.  I then created a loom video to show how the video was created:  https://www.loom.com/share/6695da2af1884af2b994db23651fbc9b. 
![Screen Shot 2023-05-08 at 9 51 34 PM](https://user-images.githubusercontent.com/44621942/236989533-9d0b6ab5-38e3-45f8-af06-01958d0c28c2.jpg)

## Searching for NPI numbers
This code performs a search on the National Plan and Provider Enumeration System (NPPES) database for National Provider Identifier (NPI) numbers for a list of healthcare providers in the Otolaryngology (ENT) field. It reads in a dataset of Otolaryngology providers, filters out non-U.S. providers, removes special characters, and creates a list of first and last names to search for NPI numbers.  The code then searches for each name pair using the npi_search function from the npi package and stores the results in a list. It flattens the search results and removes duplicates to get only distinct NPI numbers. Then, it joins the search results with the original dataset of provider names, keeping only matching NPI numbers and filters to select only Otolaryngology providers. It cleans up, selects relevant columns, and writes the final result to a CSV file.  We may still need to do some hand-searching at this point to get the names and NPI numbers.  

`npi_search_working.R` is the file uploaded to github.com.  In the ortho study we used `ortho_npi_search_working.R`.  This takes the data from the patient-facing directory `for_npi_search_from_exploratory_all_raw_subseted_state_results.xlsx` and sends it to the NPPES API.  ![Screenshot 2023-10-22 at 4 51 46 PM](https://github.com/mufflyt/mystery_shopper/assets/44621942/2c376e69-fa36-4847-9a95-0cc17a6b5152)  In the function we set the providers to be individuals in the USA.  The output from the NPPES API is saved as `ortho/data/csv/cleaned_ortho_npi_data_flattened.csv`.  We merge the original patient-facing dataframe with the NPI search results dataframe so we can use them together.  We also get some summary statistics showing we automatically could ***NOT*** get the NPI for 4,587 people or 83.8% of the sample.  
```r
> sum(result$npi == "NO MATCH FOUND")
[1] 4587
> paste0("Percentage of NO MATCH FOUND:  ", round((sum(result$npi == "NO MATCH FOUND")/nrow(result))*100, digits = 1), "%")
[1] "Percentage of NO MATCH FOUND:  83.8%"
```
There was some cleaning that needed to be done in exploratory.io, but then we had 4,442 orthopedists with unique NPI numbers and unique phone numbers.  The data now has gender, sole_proprieter, enumeration_date, zip code, and phone number.  We probably need to use the US Census Bureau subdivisions for geographical lumping.  (https://github.com/cphalpert/census-regions/blob/master/us%20census%20bureau%20regions%20and%20divisions.csv)
```r
filter(taxonomies_desc %in% c("Orthopaedic Surgery", "Orthopaedic Surgery, Adult Reconstructive Orthopaedic Surgery", "Orthopaedic Surgery, Foot and Ankle Surgery", "Orthopaedic Surgery, Hand Surgery", "Orthopaedic Surgery, Orthopaedic Surgery of the Spine", "Orthopaedic Surgery, Orthopaedic Trauma", "Orthopaedic Surgery, Pediatric Orthopaedic Surgery", "Orthopaedic Surgery, Sports Medicine"))
```
![Screenshot 2023-10-22 at 5 03 27 PM](https://github.com/mufflyt/mystery_shopper/assets/44621942/53e40746-9fb1-4e05-bfc4-491b6ddf74a5)

## Sample the Data
```r
# Group by AAO_regions and specialty before sample.  
  group_by(AAO_regions, specialty_primary) %>%
  
  # Sampling step here.  More than 10 samples by region and by specialty starts to get problematic after more than 10.  
  sample_rows(9, seed = 1978) %>%
  
  # Use humaniformat to clean the names so that matches can be made between dataframes based on names.  
  mutate(first = humaniformat::first_name(full_name)) %>%
  separate(full_name, into = c("full_name_1", "full_name_2"), sep = "\\s*\\,\\s*", remove = FALSE, convert = TRUE) %>%
  mutate(last = humaniformat::last_name(full_name_1)) %>%
  
  # Create the line of text with name, phone number, specialty, and insurance type.  
  mutate(calculation_1 = "Dr") %>%
  unite(united_column, calculation_1, last, sep = " ", remove = FALSE, na.rm = FALSE) %>%
  
  # Unite all parts of the name, specialty, etc.  
  unite(redcap_data, specialty_primary, united_column, phone_number, full_name, sep = ",  ", remove = FALSE, na.rm = FALSE) %>%
  ungroup() %>%
  
  # Amazing.  Creates a numbered row column.  
  mutate(id = 1:n()) %>%
  
  # Doubles amount of rows by stacking a copy of the rows on top of the dataframe. In this code, the . refers to the input data frame (df), and the duplicated data frame is created by binding it with itself using bind_rows(., .).
  bind_rows(., .) %>%
  
  # Add the two different insurances: BCBS and Medicaid for each person.  
  mutate(Insurance = rep(c("Blue Cross/Blue Shield", "Medicaid"), length.out = nrow(.))) %>%
  
  # Each physician has two duplicate rows with the same id number.  
  arrange(id) %>%
  select(-id) %>%
  
  # Unique row number for each row.  
  mutate(id = 1:n()) %>%
  
  # Unite all the information to upload to redcap: https://redcap.ucdenver.edu/redcap_v13.1.18/ProjectSetup/index.php?pid=28103. 
  unite(united_column, id, redcap_data, Insurance, sep = ", ", remove = FALSE, na.rm = FALSE)
```

### Matching Names to NPI numbers
'npi_api.R' and 'npi_search_working.R' are both viable options that get about 70% matches of the names to NPI numbers.  
  
## Split list up to x number of callers
See `Splitting_dataframe_to_send_to_callers.R` (see files on github)
This code reads a CSV file named "for_each_caller.csv" located at "/Users/tylermuffly/Dropbox (Personal)/Mystery shopper/mystery_shopper/Corbi study/ENT/For_each_caller" directory and splits the data into eight parts. Each split is saved as a separate XLSX file in the same directory.  The split() function is used to split the data frame into 8 parts based on row numbers. The cut() function is used to create a factor variable that assigns each row to one of the 8 groups. The names() function is then used to get the names of each group.  The for-loop iterates through each group, creates a file name for each group based on the group name, date, and row number. The write.xlsx() function is used to save each split data frame as a separate XLSX file in the output directory.  The output files will have names like "Sophie_2023-05-06_153_rows_1_to_19.xlsx", where "Sophie" is the name of the split, "2023-05-06" is the current date, "153" is the number of rows in the split, and "1_to_19" are the row IDs of the first and last rows in the split.
![Screen Shot 2023-05-08 at 8 29 42 PM](https://user-images.githubusercontent.com/44621942/236978744-1dfa24b5-ad26-4ace-8c05-220aa2197f9e.jpg)

## Phase 1 e-mail
https://olucdenver-my.sharepoint.com/personal/hannah_kyllo_cuanschutz_edu/_layouts/15/onedrive.aspx?id=%2Fpersonal%2Fhannah%5Fkyllo%5Fcuanschutz%5Fedu%2FDocuments%2FMystery%20Caller%20Study&ga=1

## Redcap Survey
* [MysteryCallerDataEntryForm_ENT.pdf](https://github.com/mufflyt/mystery_shopper/files/11468707/MysteryCallerDataEntryForm_ENT.pdf)
* [ENTSubspecialtyMysteryCaller_DataDictionary_2023-05-12.csv](https://github.com/mufflyt/mystery_shopper/files/11468716/ENTSubspecialtyMysteryCaller_DataDictionary_2023-05-12.csv)
![Screen Shot 2023-05-12 at 8 48 59 PM](https://github.com/mufflyt/mystery_shopper/assets/44621942/24171fb7-e5bc-4171-a60c-b1de789680cd)
* [MysteryCallerDataEntryForm_Pes.pdf](https://github.com/mufflyt/mystery_shopper/files/11963391/MysteryCallerDataEntryForm_Pes.pdf)
* [PessaryServicesAtFederallyQual_DataDictionary_2023-07-05.csv](https://github.com/mufflyt/mystery_shopper/files/11963387/PessaryServicesAtFederallyQual_DataDictionary_2023-07-05.csv)

# Phase 2 - Call the validated phone numbers to get the wait time to new patient appointment 
* https://www.youtube.com/playlist?list=PLMUhma2xrRQ7IAe4HvKfzgeV52rgpifK-
* Figure 1: ![image](https://github.com/mufflyt/mystery_shopper/assets/44621942/d9eadab7-cf4c-415f-b2ea-8078317a368c) and Word document can be found in the directory.  

![Screen Shot 2023-07-06 at 9 19 23 PM](https://github.com/mufflyt/mystery_shopper/assets/44621942/6253a743-1c7c-4a18-843f-66931a10f92a)

* Handout for lab assistants: [lab_assistant_Myster Caller Protocol.pdf](https://github.com/mufflyt/mystery_shopper/files/12331058/lab_assistant_Myster.Caller.Protocol.pdf)
![Screenshot](https://github.com/mufflyt/mystery_shopper/assets/44621942/c7c97880-c628-43fd-9092-2159b3660818)

* Clinical vignette for lab assistants: [lab_assistant_OBGYN Mystery Caller Script.pdf](https://github.com/mufflyt/mystery_shopper/files/12331065/lab_assistant_OBGYN.Mystery.Caller.Script.pdf)
![Screenshot 2023-08-13 at 8 27 01 PM](https://github.com/mufflyt/mystery_shopper/assets/44621942/d3f1a536-aff1-43e1-889c-65533d907c48)

# Analysis using Marcos' Code
* Please see Marcos' original code in the directory folder: Test-Marcos-v6---Reviewer-comments-+-Revision-2.html
* https://youtu.be/j0Om2qO7diQ
* '/Users/tylermuffly/Dropbox (Personal)/Mystery shopper/mystery_shopper/Corbi study/ENT/code/Marcos/final ENT results of Marcos code.Rmd':  Permission was given by Marcos for us to change his code and use it for the ENT study.  
* Statistics uploaded as an html file: "final_ENT_results_of_Marcos_code1.html" and code uploaded as "final_ENT_results_of_Marcos_code1.rmd".  We found that a Poisson model worked the best for the ENT study.
* I did like to create one formula and then use that for every model so it stayed the same.  Calling a summary of the model gives the p-values.  The tab_model create a table of coefficients that can be copied and pasted to Excel.  The `easystats` library was especially helpful here.  
```
formula <- as.formula(paste("days ~ insurance + Age + academic_affiliation + AAO_regions + title + gender + central + specialty + (1 | name)"))

poisson <- glmer(formula = formula,
  data = df3,
  family = poisson(link = "log"),
  nAGQ = 0,
  verbose = 0L)

summary(poisson)
tab_model(poisson, transform = "exp") #Easiest to copy and paste to word.  
performance(poisson)
```
* We then need to check the assumptions of the Poisson model.
* Checking the assumptions of a Poisson regression model involves several steps. Here are some key checks you should do:
1. **Mean equals variance:** The Poisson model assumes the mean of the distribution is equal to its variance. This is known as equidispersion. If the variance is greater than the mean, the data are overdispersed. If the variance is less than the mean, the data are underdispersed. You can check this by comparing the mean and the variance of your outcome variable. If they're not roughly equal, a negative binomial model might be a better choice.

```
logLik_model <- logLik(poisson)
residual_deviance <- -2 * logLik_model
num_observations <- nrow(df3)
num_fixed_effects <- length(fixef(poisson))
num_random_effects <- length(unlist(VarCorr(poisson)))
residual_df <- num_observations - num_fixed_effects - num_random_effects

dispersion_parameter <- residual_deviance / residual_df
print(dispersion_parameter)


check_overdispersion(poisson)
```

3. **Independence of events:** The Poisson model assumes that the events are independent, meaning that an event does not affect the probability of the next event. This should be considered in the study design phase and is typically assessed by examining whether the data are collected independently.

4. **Linearity of log counts:** The Poisson model assumes a linear relationship between the natural log of the expected count and the predictor variables. This assumption can be checked by plotting the residuals versus the predicted values. There should not be a pattern in the plot. A non-linear pattern might suggest that the log-linear model is not appropriate.
```
# Predicted values
fitted_values <- fitted(poisson)

# Residuals
residuals <- residuals(poisson, type = "pearson")

# Plot
plot(fitted_values, residuals, 
     xlab = "Fitted values", 
     ylab = "Residuals")
abline(h = 0, lty = 2)
```

5. **Non-negative counts:** The outcome variable in a Poisson regression should be non-negative counts. This is an inherent assumption of the model, as it's designed to model count data.

7. **No high multicollinearity:** Although not specific to Poisson regression, multicollinearity can cause issues in the estimation of regression coefficients. Multicollinearity exists when predictor variables are highly correlated. Variance inflation factor (VIF) is a common way to check for multicollinearity.
```
# Calculate VIF
vif(poisson)
result <- check_collinearity(poisson)
result
plot(result)
```

This was very helpful: https://easystats.github.io/see/articles/performance.html#checking-model-assumptions.  
```
result <- binned_residuals(poisson) #The data is non-parametric so the residuals will not be normally distributed.  
result
plot(result)

result <- check_collinearity(poisson)
result

result <- check_outliers(poisson)
result

check_overdispersion(poisson)
qqnorm(resid(poisson)) #Q-Q Plot of the residuals
qqline(resid(poisson)) #Q-Q Plot of the residuals with a line
check_autocorrelation(poisson)
check_collinearity(poisson)
check_singularity(poisson)
```
  
* `sjPlot` was a super helpful package in creating these images.![image](https://github.com/mufflyt/mystery_shopper/assets/44621942/cea0e7ca-7328-49be-9f1a-5df83c687c78)

* Figures for the Data
![Screenshot 2023-07-23 at 8 38 51 PM](https://github.com/mufflyt/mystery_shopper/assets/44621942/25006ad3-493c-44aa-b53a-66a4b0158d89)

![line_plot](https://github.com/mufflyt/mystery_shopper/assets/44621942/9f4f5387-9ff1-45f6-a7b4-dd8475a073b1)
Ideally, I want to put a trend line on this but I can't figure out how to do so.  Code for the line plot:
```
df3 <- df3 %>%
  mutate(insurance = fct_relevel(insurance, "Blue Cross/Blue Shield", "Medicaid"))

line_plot <- ggplot(df3, aes(x = insurance, y = days)) +
  geom_point() +
  geom_line(aes(group = npi), color = "gray80") +
  ggtitle("Overall Comparison of waiting times") +
  ylab("Waiting Times in Days (Log scale)") +
  scale_y_log10() +
  theme_minimal() +
  theme(axis.title.x = element_blank()); line_plot

ggsave(filename = "/Users/tylermuffly/Dropbox (Personal)/Mystery shopper/mystery_shopper/Corbi study/ENT/Figures/line_plot.jpeg", plot = line_plot, dpi = 300)
```

Poisson model estimates:
![model_plot](https://github.com/mufflyt/mystery_shopper/assets/44621942/21831d16-3fa7-4770-95fa-6df3b78eb570)

Code to create the plot of estimates using `sjPlot` and `broom`:
```
# Load the necessary packages
library(ggplot2)
library(broom)

# Use broom's tidy function to create a data frame of the coefficients
coefficients_df <- tidy(poisson)
coefficients_df <- coefficients_df[!(coefficients_df$term %in% c("(Intercept)", "sd__(Intercept)")), ]
coefficients_df$estimate <- exp(coefficients_df$estimate)

# Plot the model
p <- plot_model(poisson, 
                type = "est", 
                transform = "exp", 
                show.values = TRUE,
                vline.color = "blue",
                value.offset = 0.45,  # Adjust this value to your liking
                dot.size = 1,
                line.size = 0.9,
                title = "Model Coefficients",
                axis.title = "Incidence Rate Ratios")

# Customizing with ggplot2
p + theme_minimal() +
    theme(text = element_text(size=12),
          plot.title = element_text(face="bold"),
          axis.title.x = element_text(vjust = -0.5),
          axis.title.y = element_text(vjust = 0.5),
          legend.position = "none") +
    labs(x="Incidence Rate Ratios",
         y="Predictors",
         title="Poisson Regression\n Model Coefficients") +
    scale_y_discrete(labels = function(x) stringr::str_to_title(stringr::str_remove_all(gsub("_", " ", x), "[[:punct:]]")))# Replace underscore with space in variable names

# Save the plot
ggsave(filename = "Corbi study/ENT/Figures/model_plot.png", plot = p, width = 8, height = 6, dpi = 300)
```

Interactions:
![insuranceinteractionCentral_plot](https://github.com/mufflyt/mystery_shopper/assets/44621942/48ac6815-3539-4cc1-9db9-be86306671c2)

* These `emmeans` figures are easier to read IMHO:
![insuranceinteractionsubspecialty_comparison_plot](https://github.com/mufflyt/mystery_shopper/assets/44621942/9dcae555-2fad-4fd4-8dbf-bd848a0de2ab)

Code to create figures:
```
edata <- emmeans(poisson, ~ insurance | specialty, 
                 type = "response") %>% 
  as.data.frame()

ggplot(edata, aes(x = specialty, y = rate))+
  geom_point(aes(color = insurance), size = 2, stroke = 2,
                 position = position_dodge(width=0.2))+
  geom_errorbar(aes(ymin = asymp.LCL, ymax = asymp.UCL, 
                    color = insurance), width = 0.2,
                position = position_dodge(width=0.2))+
  ylim(15,75)+
  ggtitle("Estimated Marginal Means - Insurance Type")+
  ylab("Estimated Marginal Means for Waiting Time in Days\n Mean ± 95% CI")+
  theme_minimal() + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1, size = 8, color = "black"), legend.position = "bottom")+
  scale_x_discrete(labels = function(x) gsub(" ", "\n", x))

# Save the plot with specific dimensions
ggplot2::ggsave(filename = "Corbi study/ENT/Figures/insuranceinteractionsubspecialty_comparison_plot.png", width = 10, height = 6, bg = "transparent")
```

Usually the graph above should be good enough, but people always want to conduct statistical tests.  This looks at the statistically significant difference of interactions in a number form:
```
emmeans::emmeans(object = poisson, 
                 specs = pairwise~ insurance | specialty, 
                 type = "response")
```
```
> emmeans::emmeans(object = poisson, specs = pairwise~ insurance | specialty, 
+                  type = "response")
$emmeans
specialty = Facial Plastic and Reconstructive Surgery:
 insurance              rate   SE  df asymp.LCL asymp.UCL
 Blue Cross/Blue Shield 26.5 4.16 Inf      19.5      36.1
 Medicaid               28.1 4.40 Inf      20.7      38.2

specialty = General Otolaryngology:
 insurance              rate   SE  df asymp.LCL asymp.UCL
 Blue Cross/Blue Shield 27.2 4.22 Inf      20.1      36.9
 Medicaid               28.9 4.47 Inf      21.3      39.1

specialty = Head and Neck Surgery:
 insurance              rate   SE  df asymp.LCL asymp.UCL
 Blue Cross/Blue Shield 24.8 4.15 Inf      17.9      34.5
 Medicaid               26.3 4.39 Inf      19.0      36.5

specialty = Laryngology:
 insurance              rate   SE  df asymp.LCL asymp.UCL
 Blue Cross/Blue Shield 30.8 4.90 Inf      22.5      42.0
 Medicaid               32.6 5.18 Inf      23.8      44.5

specialty = Neurotology:
 insurance              rate   SE  df asymp.LCL asymp.UCL
 Blue Cross/Blue Shield 40.1 6.66 Inf      29.0      55.6
 Medicaid               42.5 7.05 Inf      30.7      58.8

specialty = Pediatric Otolaryngology:
 insurance              rate   SE  df asymp.LCL asymp.UCL
 Blue Cross/Blue Shield 48.5 7.50 Inf      35.9      65.7
 Medicaid               51.4 7.94 Inf      38.0      69.6

specialty = Rhinology:
 insurance              rate   SE  df asymp.LCL asymp.UCL
 Blue Cross/Blue Shield 23.6 3.86 Inf      17.2      32.6
 Medicaid               25.0 4.09 Inf      18.2      34.5

Results are averaged over the levels of: academic_affiliation, AAO_regions, title, gender, central 
Confidence level used: 0.95 
Intervals are back-transformed from the log scale 

$contrasts
specialty = Facial Plastic and Reconstructive Surgery:
 contrast                            ratio     SE  df null z.ratio p.value
 (Blue Cross/Blue Shield) / Medicaid 0.944 0.0155 Inf    1  -3.491  0.0005

specialty = General Otolaryngology:
 contrast                            ratio     SE  df null z.ratio p.value
 (Blue Cross/Blue Shield) / Medicaid 0.944 0.0155 Inf    1  -3.491  0.0005

specialty = Head and Neck Surgery:
 contrast                            ratio     SE  df null z.ratio p.value
 (Blue Cross/Blue Shield) / Medicaid 0.944 0.0155 Inf    1  -3.491  0.0005

specialty = Laryngology:
 contrast                            ratio     SE  df null z.ratio p.value
 (Blue Cross/Blue Shield) / Medicaid 0.944 0.0155 Inf    1  -3.491  0.0005

specialty = Neurotology:
 contrast                            ratio     SE  df null z.ratio p.value
 (Blue Cross/Blue Shield) / Medicaid 0.944 0.0155 Inf    1  -3.491  0.0005

specialty = Pediatric Otolaryngology:
 contrast                            ratio     SE  df null z.ratio p.value
 (Blue Cross/Blue Shield) / Medicaid 0.944 0.0155 Inf    1  -3.491  0.0005

specialty = Rhinology:
 contrast                            ratio     SE  df null z.ratio p.value
 (Blue Cross/Blue Shield) / Medicaid 0.944 0.0155 Inf    1  -3.491  0.0005

Results are averaged over the levels of: academic_affiliation, AAO_regions, title, gender, central 
Tests are performed on the log scale 
```

## Meeting for the callers and team
```r
Hi Team, 

We will be meeting in the next week or so to discuss the study and our anticipated "calling" May 8 - May 12. During our Zoom, we will discuss the study, its aims, methods, and individual responsibilities. It will be roughly 30-45 minutes max. 

Please fill out the When2Meet form within the next 24-48 hours, or let me know if you are unable to still participate. https://www.when2meet.com/?19887642-Rc5OV

In the meantime, I'm happy to answer any questions you may have, so please reach out. 

Thank you, 

Michaele Francesco Corbisiero
(626) 646-9087
```

## End of Phase 1 email
```r
Hi Dr. Muffly,

Please find links to the completed phase 1 data attached. 

(1) Mayu Screening Call List.xlsx
(2) Ellie Screening Call List.xlsx
(3) Natalya Screening Call List.xlsx
(4) Nelly Screening Call List.xlsx
(5) Yasmine Screening Call List.xlsx
(6) Wyanet Screening Call List.xlsx

I reviewed each of the entries and sorted through the full ACOG calling list to either exclude or include each physician. I have attached an "ACOG Calling List with Exclusions" in which I highlighted the physicians to be excluded. I also went through and deleted these exclusions to create an "ACOG Calling List Final". It looks like after exclusions we have 623 physicians remaining (excluded ~180).

Best,

Hannah Kyllo
University of Colorado School of Medicine
MD Candidate, Class of 2024
623-249-9220 Mobile
hannah.kyllo@cuanschutz.edu
```

## Start of Phase 2
```r
Hi team!

Tomorrow, Monday August 14, we will begin calling clinics for our OB/GYN mystery caller study. Each of you has been assigned ~178 calls to make. Please find a link to an excel spreadsheet with your individualized calling assignments below. 

Phone Call Assignment: (6) sophie_whitehead_2023-08-13_13-28-59_177_rows_7_to_1239.xlsx
REDCap Login: https://redcap.ucdenver.edu/

Please see the attached Mystery Caller Protocol for step-by-step instructions on how to make your calls and record your data in REDCap. We did review most of this during our meeting last Thursday, however a few pieces of information are new, based on your excellent questions during the meeting, so please review the protocol document prior to starting your calls. I have also attached a link to a video below in which Dr. Muffly talks through the basics of making your calls and recording your data (similar to our discussion on Thursday). Although this video was made for a prior study, the principles are the same, and it can serve as an additional tool to refresh your memory on how to perform these tasks.

Instructions Video: https://www.youtube.com/watch?v=Y_5VjxPKJF0&ab_channel=TylerMuffly

As a reminder, you will have until Friday, August 18 at 5 PM to complete your calls. Whatever you do, please do NOT schedule actual appointments during these calls. Please reach out to me if you have any questions at all, no matter how small. I am here to help and support you!

Best,

Hannah Kyllo
```

## Start calling instructions
Send e-mail with all the excel files created by: 'Splitting_dataframe_to_send_to_callers.R'.  
```r
Hello everyone,

I've attached your calling assignments with your name or e-mail.  There are eight callers, and each of you has 153 calls to make by the end of business on Friday, May 12, 2023.  Whatever you do, please do NOT make actual appointments.  

Please make sure you have signed up for REDcap access:
https://cctsi.cuanschutz.edu/resources/informatics/redcap-resources#tutorials
https://redcap.ucdenver.edu/surveys/?s=wcIyV5ajVM


The redcap login can be found here:  
https://redcap.ucdenver.edu/ and the project name is "ENT subspecialty mystery caller."  Please see the left-handed rail where it says "Add/Edit Records."  Click the green button that says "Add New Record".  Type in the physician's name, and you are ready.  Here is a link to a video about how to do the calling:  

https://youtu.be/miW_03ZqqEE
```
## Nightly e-mail to the team
```r
Dear All,

I appreciate your help today calling the ENT offices.  It was a slow start due to REDCap access issues, with 61 offices called on Monday (May 8).  We apologize for not making sure everyone had access before starting.  Please let us know if your REDCap access remains limited.  

A few simple reminders:
Please don't make any appointments.  This is out of respect for the ENT practices and actual patients.  
If you are on hold for five minutes, you can just hang up and mark this in the exclusions.  
Analyzing the data, the mean time for a new patient appointment is 29.5 days with a standard deviation of 31 days.  

Do not hesitate to reach out if you have any questions or concerns.  

Thanks,
Muffly
720-810-9863
```

## Second day calling e-mail
```
Dear All,

A few great questions came up today:

Q:  The office that I just called was for neurotology, and the scheduler informed me that the physician is not seeing patients for dizziness under any circumstances, regardless of insurance. So I was thinking that the result for Medicaid if I were to call again would most likely be the same
A:I agree. If you could write something like that in the notes section, we can exclude them in an “other” category. 

Q: If we call an office for BCBS for example and an exclusion applies like needing a referral or the number is disconnected, do we need to call that same number again for Medicaid, or do we just put in another data form with the same exclusion?
A: We should Google search the physician’s name for a second call if the number is disconnected. Then add that to the notes section.

Please do your best to work around the demand for a referral for a theoretical next available date. “Can you give me A ball park figure of when the next appt may be.”  

Thanks,
Muffly
```

## Third day e-mailing
```r
Dear All,

Great job today!  Today we are up to a total of 428 records.  The mean time for a new patient appointment is 30.4 business days (SD +/- 32.6).  

Today I worked on getting NPI numbers for each physician's name as we can match demographics to NPI numbers more easily.  NPI numbers are like social security numbers for physicians created in 2005 with the start of HIPAA.  Fun fact: NPI numbers never change even if the physician moves, changes their name, etc.  I did a hand search of the otolaryngology names and found unique NPI numbers for 83.7%.  The remainder will require a little more sleuthing.  

Thank you for everyone's hard work.  

Take care, 
Muffly
```

## Not Making Our Numbers
```
Hi Michaele,

We are not going to reach the target number of calls today.  These three people are far from the required 153 calls and have yet to contact me about needing help: ME, DG, NHG.  No one has met the goal, so it was probably unrealistic.  

What do you want to do?  I see that we have a few options:
Extend the study timeline: If reaching the target number of calls seems feasible with additional time, consider extending the study period by another week or a specified duration. Communicate the new deadline to all team members, including ME, DG, and NHG. Emphasize that meeting the deadline is crucial for achieving the study goals. Failure to complete the required calls within the extended timeframe may result in certain consequences: no authorship will be given.
 
Prioritize completion of existing pairs: Instead of making calls to new providers, focus on completing the remaining Medicaid and BCBS calls already initiated. By prioritizing the completion of existing pairs, you can ensure that the data collection for these specific cases is thorough and consistent. This approach allows for a more comprehensive analysis of the completed pairs, even if the overall number of calls falls short of the initial target. 

Readjust the sample size and power: If reaching the target number of calls becomes unattainable despite the available options, consider readjusting the sample size and power of the study. Reducing the sample size can help accommodate the limitations in call numbers while still providing meaningful insights. However, it is important to carefully evaluate the impact of smaller sample size on the statistical power and the study's ability to draw valid conclusions.  We would need to talk to a statistician about this.  
As you well know, flexibility and adaptability are key in research studies, and finding the right balance between achieving study objectives and addressing practical constraints is essential.

Thoughts?

Muffly
```

## Email of concern that we are not going to finish on time.
```
I am writing to inform you of a critical update to our project timeline. We have established a new hard deadline for completing all calls, which is now set for the upcoming ***Monday.

Given the importance of these calls to the successful completion of our project, it is crucial that everyone adheres to this deadline. We understand that unforeseen circumstances may arise, and we appreciate your flexibility and diligence in working towards this goal.

However, if you foresee any difficulty in meeting this deadline, please reach out to me as soon as possible. We will do our best to provide the necessary support and assistance to help you fulfill this task.

Please note, failure to complete your assigned calls by the deadline and/or failure to communicate any potential delays may result in your removal from the project's authorship list, which we all know is an outcome no one wants.

We greatly appreciate your contributions and dedication to this project. We trust in your commitment to meet this new deadline.

Thank you for your understanding and cooperation."
```

## Review of Week 1 calling results
```r
Hello All,

Thanks for your great work this week Michaele. This week, we made 897 call attempts with the goal of reaching 1,224 calls to achieve a sufficient sample size. The attached figures provide further information. Based on my current statistics, there is no notable difference between insurance and business days for scheduling new appointments (p=0.06). It's crucial that we complete the necessary calls to confirm or refute this null hypothesis.  

Tasks remaining for the group:
* Complete remaining calls.  If you need help, please don't hesitate to reach out.  

Here are some tasks for Muffly/Corbisiero:
* Table 1 of participant and no contact physicians: Finish hand-searching the NPI numbers, as this helps us get the needed demographics from public databases.
* Table 1 participant and no contact physicians: Lookup of participant ages on healthgrades.com.
* Figure 1: Create the scatter plot of wait time for Medicaid on the y-axis and wait time for BCBS on the x-axis using Marcos' code.  
* Send a letter via the United States postal service to participating office explaining that they received a call from our mystery callers in May 2023.  
* Move REDCap to "analysis/cleanup phase."
* Finish manuscript results and write the discussion

Long-term tasks:
* Submit to an ENT journal.  CCM can make some journal recommendations.  

Thanks,
Muffly
```

## E-mail to society about incorrect phone numbers in the patient-facing database
```r
Hi Michaele,

In my opinion, the Notes section is the most informative section to read. However, we came across some errors while reviewing the information. For instance, we found listings of retired physicians, doctors who no longer practice at this location, wrong telephone numbers, and even personal physician numbers while taking phone numbers from the patient directory. We can inform AAO-HNS about these incorrect listings so that they can address the issues we found.  When we did the same project with urogyn their society was very thankful for "double checking" their patient-facing database.  

Maybe in the future, we should confirm the phone numbers somehow before having the team start making phone calls so they can be more focused.  

CCM who is the right person to pass this on to at AAO-HNS?  
```

```r
Q: Lizzie texted me today asking if there's a way to search for a physician name or number. She has updates for her calls that were done using her excel sheet and need to be uploaded to redcap. 

A: If anyone has notes they want to put in on their calls and the calls have been completed, they can search for the provider id in the "Choose an Existing Record" field. Please take a look at the redcap screenshot.  The provider id is the first number in the "upload_to_redcap" column of each Excel file given to each caller. I included a highlighted screenshot as well.   

I would like to "lock" the database to any edits within the next 48 hours so we can proceed with the analysis.  Every time we change the data, we have to re-analyze, which gets painful after a while.  Let me know if this timeline works for you, please.  

Thanks,
Muffly
```
![Screen Shot 2023-05-16 at 10 19 24 AM](https://github.com/mufflyt/mystery_shopper/assets/44621942/c4432d19-d955-4b1b-a80b-e0a4f9dd78f1)
![Screen Shot 2023-05-16 at 10 21 38 AM](https://github.com/mufflyt/mystery_shopper/assets/44621942/15e9a2b7-3d81-4639-9320-3b85863f489d)

## Cool flow chart for callers to follow from German Birth Control Study
* We should create something that looks like this.  
![Scenario-for-female-and-male-MCs-using-a-flow-chart-Note-The-green-arrows-indicate-the ppm](https://github.com/mufflyt/mystery_shopper/assets/44621942/6bc325ce-e175-4f81-ade2-2adb6745eb57)

# Export the data
* Export the data:
![Screen Shot 2023-05-08 at 8 20 28 PM](https://user-images.githubusercontent.com/44621942/236977534-3ea48f46-4114-40d6-a34a-b5c51b4c4a74.jpg)

* Export the data as a CSV with labels:
![Screen Shot 2023-05-08 at 8 23 43 PM](https://user-images.githubusercontent.com/44621942/236977942-395fca15-ef43-42ba-84d0-2fc7bba96379.jpg)

# Manuscript
## RedCAP citation
Please note that any publication that results from a project utilizing REDCap should cite grant support (NIH/NCATS Colorado CTSA Grant Number UL1 TR002535).  Please cite the publications below in study manuscripts using REDCap for data collection and management. We recommend the following boilerplate language:

Study data were collected and managed using REDCap electronic data capture tools hosted at [YOUR INSTITUTION].1,2 REDCap (Research Electronic Data Capture) is a secure, web-based software platform designed to support data capture for research studies, providing 1) an intuitive interface for validated data capture; 2) audit trails for tracking data manipulation and export procedures; 3) automated export procedures for seamless data downloads to common statistical packages; and 4) procedures for data integration and interoperability with external sources.

1PA Harris, R Taylor, R Thielke, J Payne, N Gonzalez, JG. Conde, Research electronic data capture (REDCap) – A metadata-driven methodology and workflow process for providing translational research informatics support, J Biomed Inform. 2009 Apr;42(2):377-81.

2PA Harris, R Taylor, BL Minor, V Elliott, M Fernandez, L O’Neal, L McLeod, G Delacqua, F Delacqua, J Kirby, SN Duda, REDCap Consortium, The REDCap consortium: Building an international community of software partners, J Biomed Inform. 2019 May 9 [doi: 10.1016/j.jbi.2019.103208]

Data Sources 
==========
* https://www.psc.isr.umich.edu/dis/census/Features/tract2zip/, Geographic Correspondence Engine at Missouri Census Data Center
* http://mcdc.missouri.edu/applications/geocorr2018.html
* https://www.voicesforpfd.org/find-a-provider/
* https://acogpresident.files.wordpress.com/2013/03/districtmapupdated.jpg?w=608
* http://www.exploratory.io, Sign up for student version
* https://www.jessesadler.com/post/geocoding-with-r/
* https://console.cloud.google.com/google/maps-apis/overview?pli=1
* https://learn.r-journalism.com/en/mapping/geolocating/geolocating/

## Installation and use
These are scripts to pull and prepare data. This is an active project and scripts will change, so please always update to the latest version.

```r
# Set libPaths.
.libPaths("/Users/tylermuffly/.exploratory/R/4.0")

# Load required packages.
library(janitor)
library(lubridate)
library(hms)
library(tidyr)
library(stringr)
library(readr)
library(forcats)
library(RcppRoll)
library(dplyr)
library(tibble)
library(bit64)
library(exploratory)

# Steps to produce Crosswalk_ACOG_Districts
`Crosswalk_ACOG_Districts` <- exploratory::read_delim_file("/Users/tylermuffly/Dropbox (Personal)/Mystery shopper/Crosswalk_ACOG_Districts.csv" , ",", quote = "\"", skip = 0 , col_names = TRUE , na = c('','NA') , locale=readr::locale(encoding = "UTF-8", decimal_mark = ".", tz = "America/Denver", grouping_mark = "," ), trim_ws = TRUE , progress = FALSE) %>%
  readr::type_convert() %>%
  exploratory::clean_data_frame() %>%
  mutate(State_Abbreviations = factor(State_Abbreviations))
```


# Steps to produce the output
```r
exploratory::read_delim_file("https://www.dropbox.com/s/81s4sfltiqwymq1/Downloaded%20%289035315-9050954%29%20%282019-08-13%2022.csv?raw=1" , ",", quote = "\"", skip = 0 , col_names = TRUE , na = c('','NA') , locale=readr::locale(encoding = "UTF-8", decimal_mark = ".", tz = "America/Denver", grouping_mark = "," ), trim_ws = TRUE , progress = FALSE) %>%
  readr::type_convert() %>%
  exploratory::clean_data_frame() %>%
  bind_rows(a2, a3, a4, a5, a6, a7, a8, a9, a11, a12, a13, a14, a15, a16, a17, a18, a19, a20, a21, a22, a23, a24, a25, a26, a27, a28, a29, a30, a31, a32, a33, a34, a35, a36, a37, a38, a39, a40, a41, a42, a43, a44, a45, a46, a47, a48, a49, a50, a51, a52, a53, a55, a56, a59, a60, a61, a62, a63, a64, a65, a66, b1, b2, b3, b4, b5, c1, d1, d2, Physicians_970434_940841_2020_07_25_19_08_57, Physicians_961459_940841_2020_07_25_21_23_45, Physicians_953100_940841_2020_07_26_10_13_00, Physicians_940841_930841_2020_07_26_16_43_50, Physicians_940841_930841_2020_07_26_16_43_50_1, Physicians_940841_1_2020_07_27_07_32_01, Physicians_930207_9e_05_2020_07_27_13_27_18, Physicians_918005_907225_2020_07_27_19_18_17, Physicians_905914_904000_2020_07_27_20_19_46, Physicians_906000_904000_2020_07_27_19_17_05, Physicians_918005_907225_2020_07_27_18_05_25, Physicians_918005_907225_2020_07_27_19_18_17_1, Physicians_9e_05_926360_2020_07_27_16_52_16, Physicians_917084_907225_2020_07_28_07_14_32, Physicians_905914_904000_2020_07_27_23_39_44, Physicians_917084_907225_2020_07_28_07_14_32_1, Physicians_905914_904000_2020_07_27_23_39_44_1, force_data_type = TRUE) %>%
  mutate(sub1 = recode(sub1, FPM = "Female Pelvic Medicine & Reconstructive Surgery", `Female Pelvic Medicine & Reconstructive Surgery` = "Female Pelvic Medicine & Reconstructive Surgery", PAG = "Pediatric & Adolescent Gynecology", MFM = "Maternal-Fetal Medicine", `Gynecologic Oncology` = "Gynecologic Oncology", ONC = "Gynecologic Oncology", REI = "Reproductive Endocrinology and Infertility", HPM = "Hospice and Palliative Medicine", CRI = "Gynecologic Oncology")) %>%
  group_by(userid) %>%
  fill(everything(), .direction = "down") %>%
  fill(everything(), .direction = "up") %>%
  slice(1) %>%
  distinct(userid, .keep_all = TRUE) %>%
  select(userid, name, city, state, startDate, certStatus, mocStatus, sub1, sub1startDate, sub1certStatus, sub1mocStatus, sub2certStatus, clinicallyActive, orig_sub, orig_bas) %>%
  filter(sub1certStatus %nin% c("Retired")) %>%
  filter(sub1certStatus %nin% c("Retired") & state %nin% c("ON", "AB", "AP", "BC", "GU", "HR", "MB", "NB", "NL", "NS", "OT", "PU", "QC", "VI", "SK")) %>%
  mutate_at(vars(startDate, sub1startDate, orig_sub, orig_bas), funs(year)) %>%
  filter(sub1 %nin% c("Generalist", "Hospice and Palliative Medicine", "Pediatric & Adolescent Gynecology")) %>%
  distinct(userid, .keep_all = TRUE) %>%
  filter((is.na(name) | name != "TESTING IDS TESTING IDS")) %>%
  ungroup() %>%
  filter(certStatus %nin% c("Not Certified", "Not Currently Certified", "Approved with Annual Compliance Diplomate", "Deceased Diplomate", "Ineligible Diplomate", "Probationary", "Probationary Diplomate", "Retired Diplomate") & !is.na(certStatus) & !is.na(sub1)) %>%
  separate(name, into = c("full_name", "suffix"), sep = "\\s*\\,\\s*", remove = FALSE, convert = TRUE) %>%
  mutate(first_name = word(full_name, 1, sep = "\\s+"), last_name = word(full_name, -1, sep = "\\s+")) %>%
  rename(Board_certification_year = orig_sub) %>%
  mutate(state = factor(state)) %>%
  left_join(Crosswalk_ACOG_Districts, by = c("state" = "State_Abbreviations"), ignorecase=TRUE) %>%
  select(-certStatus, -mocStatus, -State) %>%
  filter((is.na(sub2certStatus) | sub2certStatus != "Retired") & clinicallyActive %nin% c("No")) %>%
  filter(!is.na(ACOG_District_of_medical_school)) %>%
  filter(!is.na(state)) %>%
  mutate(startDate_category = cut(startDate, breaks = 3, dig.lab = 10)) %>%
  group_by(sub1, state, startDate_category) %>%
  sample_rows(1, seed = 1234546) %>%
  arrange(state) %>%
  select(-startDate, -sub1startDate, -sub1certStatus, -sub1mocStatus, -sub2certStatus, -clinicallyActive) %>%
  select(-Board_certification_year, -orig_bas) %>%
  ungroup() %>%
  mutate(website_to_search = recode(sub1, `Female Pelvic Medicine & Reconstructive Surgery` = "https://www.voicesforpfd.org/find-a-provider/", `Maternal-Fetal Medicine` = "https://www.smfm.org/members/search?page=1", `Reproductive Endocrinology and Infertility` = "https://www.reproductivefacts.org/resources/find-a-health-professional/"), Instructions = recode(sub1, `Female Pelvic Medicine & Reconstructive Surgery` = "Surf to URL and \"enter first name\" and \"enter last name\" then hit the red \"Search\" button at the bottom.  ", `Reproductive Endocrinology and Infertility` = "Surf to the URL and enter the first name and last name in each of those fields then hit the greay \"Search\" button.  Click on the name to see details.  ", `Maternal-Fetal Medicine` = "Surf to the URL and you need to manually hit \"Next\" button to scroll through the results.  ")) 
```

### Get scripts into a new RStudio project:
`New Project - Version Control - Git -` https://github.com/mufflyt/mystery_shopper.git as `Repository URL`
(Our use your preferred way of cloning/downloading from GitHub.)

# Codebook
A codebook is a technical description of the data that was collected for a particular purpose. It describes how the data are arranged in the computer file or files, what the various numbers and letters mean, and any special instructions on how to use the data properly.

* Predictors under consideration:
1. `Exclusions` - Individual fields for exclusion and inclusion.  Exclusions are: Greater than five minutes on hold, Not in the USA, Schedule not available to make appointment, Busy Signal, Phone number to FPMRS physician's personal cell phone number, Registration required, Phone number disconnected, Closed for vacation, Integrated medical system, Military patients only, Requires referral, Required to see urogyn nurse practicioner before seeing FPMRS physician, Answered by Voicemail.  
2. `Business days until appointment` - I used the bizdays package in R to do this.  
3. `Insurance type asked before offering appointment` - "He sees those patients on Mondays"
4. `Gender of first available female pelvic medicine and reconstructive surgeon` - Male or Female, 2 level categorical
5. `Accept Medicare` - PArticipating in Medicare
6. `Number of transfers`  
7. `Hold Time (min)` 
8. `Central number` - Centralized scheduling?
9. `Length of call (min)`
10. `Clinic`
11. `First Available FPMRS Physician`- Name of FPMRS physician
12. `Date called`
13. `Appt date` 
14. `Able to contact`
15. `Zip code`
16. `state.x` - numerical variable
17. `latitude.y` 
18. `longitude.y`
19.  `County`
20.  `Rurality`
21.  `Median` - Median household income
22.  `Business Days Until Appointment` - Categorical
23.  `American Congress of Obstetricians and Gynecologists District` - See map link above

[![ACOG district map](https://acogpresident.files.wordpress.com/2013/03/districtmapupdated.jpg?w=608)](https://acogpresident.files.wordpress.com/2013/03/districtmapupdated.jpg?w=608) 

* [See crosswalk between states and ACOG districts](https://github.com/mufflyt/coi/blob/dev_01/Reference_Data/Crosswalk_ACOG_Districts.csv),  A way to look at large areas of the US that are geographically close.  

This data was cleaned with the help of exploratory.io. The script is present in github called: mystery_shopper.R.  Due to COVID-19 I was unable to meet with my resident to do the analysis sitting together.  Therefore I made several screencasts to describe the process.  The videos are in a playlist on my YouTube channel.  


# `table one.R`
Creates a table 1 of demographics using the incredible arsenal::tableby package.  I tried to tune the table to the standards of Obstetrics & Gynecology but still had to do quite a bit by hand.  It would be nice if there was a +/- sign for standard deviation and the ability to drop one level in the table (e.g. only keep female and not male).  

# `script from exploratory to clean the data.R`
Does what it says.  

# `correct_lat_long`
I had this from a separate project that I had done.  Next I geocoded the street address, city, state of each FPMRS into lat and long using the Google geocoding API.  Zip codes were challenging to use and the street address, city, state information was accurate without zip codes.  Any non-matches were omitted.  These data were written to a file called locations.csv.  Many thanks to Jesse Adler for the great code.  I need to put google key.  

[![Geocoding, how does it work](https://geospatialmedia.s3.amazonaws.com/wp-content/uploads/2018/05/geocoding-graph.jpg)](https://geospatialmedia.s3.amazonaws.com/wp-content/uploads/2018/05/geocoding-graph.jpg) 

[![Zip codes, how does it work](https://www.unitedstateszipcodes.org/images/zip-codes/zip-codes.png)](https://www.unitedstateszipcodes.org/images/zip-codes/zip-codes.png) 

# Geocoding using Google
```r
# Google geocoding of FPMRS physician locations ----
#Google map API, https://console.cloud.google.com/google/maps-apis/overview?pli=1

#Allows us to map the FPMRS to street address, city, state
library(ggmap)
gc(verbose = FALSE)
ggmap::register_google(key = "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx")
ggmap::ggmap_show_api_key()
ggmap::has_google_key()
colnames(full_list)

View(full_list$place_city_state)
dim(full_list)
sum(is.na(full_list$place_city_state))

locations_df <- ggmap::mutate_geocode(data = full_list, location = place_city_state, output="more", source="google")
locations <- tibble::as_tibble(locations_df) %>%
   tidyr::separate(place_city_state, into = c("city", "state"), sep = "\\s*\\,\\s*", convert = TRUE) %>%
   dplyr::mutate(state = statecode(state, output_type = "name"))
 colnames(locations)
 write_csv(locations, "/Users/tylermuffly/Dropbox/workforce/Rui_Project/locations.csv")
locations <- readr::read_csv("/Users/tylermuffly/Dropbox/workforce/Rui_Project/locations.csv")

head(locations)
dim(locations)  #See how many FPMRS offices you lost when could not be geocoded.
View(locations)
```

The mailing list will be kept on the RedCAP database.  

RedCAP database is used to store the data and enter it in real-time.  
https://redcap.ucdenver.edu/redcap_v9.5.23/index.php?pid=17708

The study was written using the STROBE checklist:
https://www.strobe-statement.org/index.php?id=available-checklists

# Statistics
### Power Analysis
<img width="234" alt="Equations" src="https://github.com/mufflyt/mystery_shopper/assets/44621942/dbd6673e-399b-49da-97dc-f0b6eb80184e">
`Figure_1_Equation.Rmd`.  
* Reference:  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8391881/ AND http://www.psycholosphere.com/Determining%20sample%20size%20by%20Glen%20Israel.pdf

![Screen Shot 2023-06-16 at 9 53 26 PM](https://github.com/mufflyt/mystery_shopper/assets/44621942/eb907e0d-0c54-4ecf-924f-588698770931)
![Screen Shot 2023-06-16 at 9 53 56 PM](https://github.com/mufflyt/mystery_shopper/assets/44621942/3e6b8bc6-d505-4b00-9313-e800c3810c45)

### Linear mixed regression model
We will need to evaluate the data using a mixed linear regression model.  This is because the data is nested with two calls to the same provider.  Therefore we need to control for calling the same provider twice.  This can be done using the `lmer`, `lmerTest`, and `performance` packages for R.  
![image](https://github.com/mufflyt/mystery_shopper/assets/44621942/f5ba5d5d-17c5-431e-886c-cb902c3dc4e0)
![Screen Shot 2023-07-06 at 7 21 29 PM](https://github.com/mufflyt/mystery_shopper/assets/44621942/2216f6eb-0ee6-4342-a317-6c920d4b438a)



We can create our custom equation using `Figure_1_Equation.Rmd`.  This rmarkdown file is in the directory and should be knit. 
![Screen Shot 2023-07-06 at 2 29 11 PM](https://github.com/mufflyt/mystery_shopper/assets/44621942/757722cc-b009-4890-af11-e83914722fcd)


Reference
==========
* https://www.merritthawkins.com/uploadedFiles/MerrittHawkins/Content/Pdf/MerrittHawkins_PhysiciansFoundation_Survey2018.pdf, Merritt-Hawkins Physicians Foundation Survey

Society Patient-Facing Directory Web Pages
==========
* https://web.archive.org/web/20070701222152/http://www.wcn.org/interior.cfm?diseaseid=13&featureid=4
* http://asrm.org
* https://www.smfm.org/members/search
* http://voicesforpfd.org

Get at least one person to call for each subspecialty.  Medical students?  All should probably be women or men.  Do an elective with Muffly in December to make the phone calls.  Able to work from home with the redcap database and a telephone.  Scenarios would be: 4 cm simple cyst, infertility, prior CHTN, and SUI.  

# How to pick physicians to call based off nomogram code
```r
dplyr::group_by(Match_Status, white_non_white, Gender) %>%  #selected equal numbers of people with various match_status, white_non_white, and genders.  
  exploratory::sample_rows(1) %>%
  as_tibble()
```

# Use of Mechanical Turk to get phone numbers from society web pages (Kati and Muffly Search for Physician Phone Numbers)
```r
<!-- You must include this JavaScript file -->
<script src="https://assets.crowd.aws/crowd-html-elements.js"></script>

<!-- For the full list of available Crowd HTML Elements and their input/output documentation,
      please refer to https://docs.aws.amazon.com/sagemaker/latest/dg/sms-ui-template-reference.html 
      
      
      Kati_Turner_calling_study
      TYLER THIS WOULD BE YOUR INPUT FILE
      
      
      -->

<!-- You must include crowd-form so that your task submits answers to MTurk -->
<crowd-form answer-format="flatten-objects">

  <p>
    Please search for this OBGYN physician first name, last name at this url:
    </p>
    
    <strong>  
      <p>    
        Website to Search: ${website_to_search}
      </strong>  
      </p>
    
    <strong>  
      <p>    
        Instructions: ${Instructions}
      </strong>  
      </p>

    <strong>

        <!-- The residency name you want researched when you publish a batch with a CSV input file containing multiple companies  -->
        <p>
        First name: ${first_name}  
          </p>
    
      <strong>  
      <p>    
        Last name: ${last_name}
      </strong>  
      </p>

    <strong>
        <p>
       State: ${state}
      </strong>  
      </p>
      
        </p>
    <p>
  
      </strong>  
      </p>
      
    <p>
        
    </p>
 <div>
     
                     <p><strong>Please copy and paste the ten digit phone number:</strong></p>
<p><crowd-input name="Phone_number" placeholder="please copy and paste phone number, (example: 555-234-5678)" ></crowd-input></p>

                <p><strong>Please copy and paste the first and the last name from the "Name" field:</strong></p>
<p><crowd-input name="physician_name" placeholder="please copy and paste the name, (NAME EXAMPLE)" required></crowd-input> </p>

                <p><strong>Please copy and paste the street address:</strong></p>
<p><crowd-input name="address" placeholder="please copy and paste state, (example: 777 Bannock Street)" ></crowd-input></p>

                <p><strong>Please copy and paste the city:</strong></p>
<p><crowd-input name="city" placeholder="please copy and paste state, (example: Anchorage)" ></crowd-input></p>

                <p><strong>Please copy and paste the state:</strong></p>
<p><crowd-input name="State" placeholder="please copy and paste state, (example: AK)" ></crowd-input></p>

                <p><strong>Please copy and paste the five-digit zip code:</strong></p>
<p><crowd-input name="zip" placeholder="please copy and paste zip, (example: 90210)" ></crowd-input></p>

<p><crowd-input name="comments" placeholder="Any comments or suggestions." ></crowd-input> </p>
    <p>
        Thank you!  
    </p>

            </div>
```
# Search for NPI related to physicians (Kati and Muffly Search for NPI number)
```r
<!-- You must include this JavaScript file -->
<script src="https://assets.crowd.aws/crowd-html-elements.js"></script>

<!-- For the full list of available Crowd HTML Elements and their input/output documentation,
      please refer to https://docs.aws.amazon.com/sagemaker/latest/dg/sms-ui-template-reference.html 
      
      
      merged_mturk_residencies_for_medical_school_search_on_mturk
      TYLER THIS WOULD BE YOUR INPUT FILE
      
      
      -->

<!-- You must include crowd-form so that your task submits answers to MTurk -->
<crowd-form answer-format="flatten-objects">

  <p>
    Please search for this OBGYN physician first name, last name, and state at this url:
    "https://npiregistry.cms.hhs.gov/registry/?" :

    <strong>

        <!-- The residency name you want researched when you publish a batch with a CSV input file containing multiple companies  -->
        <p>
        First name: ${first_name}  
          </p>
    
      <strong>  
      <p>    
        Last name: ${last_name}
      </strong>  
      </p>

    <strong>
        <p>
       State: ${state}
      </strong>  
      </p>
      
        </p>
    <p>
  
      </strong>  
      </p>
      
    <p>
        
    </p>
 <div>
     
                     <p><strong>Pick the top result.  Please copy and paste the ten digit "NPI number":</strong></p>
<p><crowd-input name="NPI" placeholder="please copy and paste NPI number, (example: 1234567899)" ></crowd-input></p>

                <p><strong>Please copy and paste the first and the last name from the "Name" field:</strong></p>
<p><crowd-input name="physician_name" placeholder="please copy and paste the name, (NAME EXAMPLE)" required></crowd-input> </p>

                <p><strong>Please copy and paste the state from the "Primary Practice Address":</strong></p>
<p><crowd-input name="State" placeholder="please copy and paste state, (example: CO)" ></crowd-input></p>

                <p><strong>Please copy and paste the taxonomy code from the "Primary Taxonomy":</strong></p>
<p><crowd-input name="Taxonomy" placeholder="please copy and paste taxonomy, (example: Obstetrics and Gynecology)" ></crowd-input></p>

<p><crowd-input name="comments" placeholder="Any comments or suggestions." ></crowd-input> </p>
    <p>
        Thank you!  
    </p>

            </div>
```

Abstract
==========
OBJECTIVE:  To evaluate the mean appointment wait time for a new patient visit at outpatient female pelvic medicine and reconstructive surgery offices for US women with the common and non-emergent complaint of uterine prolapse.
 
METHODS:  The American Urogynecologic Society “Find a Provider” tool was used to generate a list of female pelvic medicine and reconstructive surgery (FPMRS) offices across the United States.  Each of the 427 unique listed offices was called. The caller asked for the soonest appointment available for her mother, who was recently diagnosed with uterine prolapse.  Data for each office were collected including date of soonest appointment, FPMRS physician demographics, and office demographics.  Mean appointment wait time was calculated.  
 
RESULTS:  Four hundred twenty-seven FPMRS offices were called in 46 states plus the District of Columbia.  The mean appointment wait time was 23.1 business days for an appointment (standard deviation 19 business days).  The appointment wait time was six days longer when seeing a female FPMRS physician compared to a male FPMRS physician (mean 26 vs. 20 business days, p<0.02).  There was no difference in wait time by day of the week called. 
 
CONCLUSION:  Typically, a woman with uterine prolapse can expect to wait at least four weeks for a new patient appointment with an FPMRS board certified physician listed on the American Urogynecologic Society website.  First available appointment is more often with a male physician.  A patient can expect to wait six days longer to see a female FPMRS physician.   


We wrote the paper on GoogleDocs.  https://docs.google.com/document/d/1rg6Mf4ZHYE5o3s4v1CIz-KRAm7NSHbDIPWPyU3ezaws/edit?usp=sharing
GoogleDocs and Endnote do not play well together.  Therefore we used Endnote for references once the final product was exported into Microsoft Word.  I have an endnote x8 group called `MysteryCallerStudy` in the `gethispainthingdone.enlp` library.  I found the easiest way to use endnote was to click on the Online Search --> PubMed(NLM) and search for the articles that way.  Then I could pull the reference into the Word document.  

# Rejections
## Green Journal
[Muffly comments.docx](https://github.com/mufflyt/mystery_shopper/files/11987077/Muffly.comments.docx)

## Cover Letters for Submission
[coverletter.docx](https://github.com/mufflyt/mystery_shopper/files/11987064/coverletter.docx)
[Manuscript Cover Letter .docx](https://github.com/mufflyt/mystery_shopper/files/11987076/Manuscript.Cover.Letter.docx)

## Proofs
[YMOB14983_proof.pdf](https://github.com/mufflyt/mystery_shopper/files/11987057/YMOB14983_proof.pdf)

# Closing Time
* Move REDCap to "analysis/cleanup phase."
![Screen Shot 2023-05-13 at 10 35 24 AM](https://github.com/mufflyt/mystery_shopper/assets/44621942/c1e8a18b-44f6-4863-969c-b3793b0458b7)
